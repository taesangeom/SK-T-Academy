{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taesangeom/SK-T-Academy/blob/main/DL/CNN/cnn_optuna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gjg9xinFqHMY",
        "outputId": "f97bc89d-b9c8-413f-9c9e-8ef2b19112e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.35)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Downloading optuna-4.0.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.3 colorlog-6.8.2 optuna-4.0.0\n"
          ]
        }
      ],
      "source": [
        "# colab에서 할 때는 optuna를 설치해야 합니다.\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "rkM4BgfuqQrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "s7yK_n2aqXGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_X, train_y), ( test_X, test_y) = fashion_mnist.load_data()\n",
        "print(train_X.shape)\n",
        "print(train_y.shape)\n",
        "print(test_X.shape)\n",
        "print(test_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMxPRejRqZIU",
        "outputId": "501858b0-c5f3-4c91-b586-5bcde3063c6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리\n",
        "train_X = train_X /255.0\n",
        "test_X  = test_X / 255.0\n",
        "\n",
        "print(train_X.shape)\n",
        "print(train_X[0].shape)\n",
        "#train_X = train_X.reshape(60000, 28, 28,1)\n",
        "train_X = train_X.reshape(-1, 28, 28,1) # 3d -- >4d\n",
        "test_X = test_X.reshape(-1, 28,28,1)\n",
        "print(train_X.shape)\n",
        "print(train_X[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCzhmKryqh3O",
        "outputId": "b4519ea2-a308-421f-a442-b2430c9d7344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(28, 28)\n",
            "(60000, 28, 28, 1)\n",
            "(28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 코드가 조금 길어지니까...모듈을 간단히 불러오겠습니다.\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout"
      ],
      "metadata": {
        "id": "lq1FnF9Oqy9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_vgg_fashion = tf.keras.Sequential(\n",
        "    [\n",
        "        # 원본 입력을 기준으로 설계 : 224 224 RGB --> (224,224,3)\n",
        "        # ==> 28 , 28 , 1\n",
        "        Conv2D( input_shape=(28,28,1), kernel_size=(3,3),\n",
        "               filters = 64, padding=\"same\", activation=\"relu\"),\n",
        "        Conv2D(  kernel_size=(3,3),\n",
        "               filters = 64, padding=\"same\", activation=\"relu\"),\n",
        "        MaxPool2D( pool_size=(2,2), strides=(2,2)),\n",
        "\n",
        "        Conv2D(  kernel_size=(3,3),\n",
        "               filters = 128, padding=\"same\", activation=\"relu\"),\n",
        "        Conv2D(  kernel_size=(3,3),\n",
        "               filters = 128, padding=\"same\", activation=\"relu\"),\n",
        "        MaxPool2D( pool_size=(2,2), strides=(2,2)),\n",
        "\n",
        "        Conv2D(  kernel_size=(3,3),\n",
        "               filters = 256, padding=\"same\", activation=\"relu\"),\n",
        "        Conv2D(  kernel_size=(3,3),\n",
        "               filters = 256, padding=\"same\", activation=\"relu\"),\n",
        "        Conv2D(  kernel_size=(3,3),\n",
        "               filters = 256, padding=\"same\", activation=\"relu\"),\n",
        "        MaxPool2D( pool_size=(2,2), strides=(2,2)),\n",
        "\n",
        "        # Conv2D(  kernel_size=(3,3),\n",
        "        #        filters = 512, padding=\"same\", activation=\"relu\"),\n",
        "        # Conv2D(  kernel_size=(3,3),\n",
        "        #        filters = 512, padding=\"same\", activation=\"relu\"),\n",
        "        # Conv2D(  kernel_size=(3,3),\n",
        "        #        filters = 512, padding=\"same\", activation=\"relu\"),\n",
        "        # MaxPool2D( pool_size=(2,2), strides=(2,2)),\n",
        "\n",
        "        # Conv2D(  kernel_size=(3,3),\n",
        "        #        filters = 512, padding=\"same\", activation=\"relu\"),\n",
        "        # Conv2D(  kernel_size=(3,3),\n",
        "        #        filters = 512, padding=\"same\", activation=\"relu\"),\n",
        "        # Conv2D(  kernel_size=(3,3),\n",
        "        #        filters = 512, padding=\"same\", activation=\"relu\"),\n",
        "        # MaxPool2D( pool_size=(2,2), strides=(2,2)),\n",
        "        ##====> 기본적인 이미지가 가지고 있는 특징 추출!!!!\n",
        "\n",
        "        # 분류를 위한 NN\n",
        "        # 1) 특징 추출 네트워크와 분류 네트워크 연결 : Flatten\n",
        "        Flatten(),\n",
        "        # 2) 분류를 위한 HL\n",
        "        Dense( units = 4096, activation=\"relu\"),\n",
        "        Dense( units = 4096, activation=\"relu\"),\n",
        "        # 3) 출력용으로 대회가 1000가지 분류.,...\n",
        "        Dense( units = 10, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "model_vgg_fashion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_Sp6qYIqmGV",
        "outputId": "e486641d-df5c-45e1-bb0e-7d6b6322cd8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Sequential name=sequential, built=True>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 위의 간단한 구조를 바탕으로 좀 더 디테일한 구조들에 대해서 실험!!!\n",
        "# 1. 내가 무엇을 보고 최적화를 할지 함수로 설정!!!!\n",
        "#    ML : 단순 파라미터들의 조합을 가지고 실험!!!!!\n",
        "#    DL : 모데르이 구조에 대한 파라미터들을 가지고 실험!!!!\n",
        "#         + 노드의 수, lr, AF etc\n",
        "# ===> 내가 하려는 것에 맞는 함수를 직접 만들어서 사용을 해야 함!!!!!!"
      ],
      "metadata": {
        "id": "D583EPi3qvQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "978pP35jrejx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 참고 : 지극히 개인적인 실험 방식!!!"
      ],
      "metadata": {
        "id": "0biCESdirVro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step1) optuna가 주는 파라미터에 맞는 모델 구조를 생성하는 함수!!!!\n",
        "# ===> 입력\n",
        "#  1) 1번 conv layer에서 몇 가의 conv을 진행할지 실험(2,3) +\n",
        "#  2) 2번 conv layer에서 몇 개의 conv을 진행할지 실험,,,\n",
        "#  3) dropout 같은 구조에 있어서도,,rate 테스트,,,\n",
        "#  4) 분류에 대한 Dense에서,,,node수를 조정하고 싶다!!!\n",
        "# etc....\n",
        "# ==> 실험을 하고자 하는 방향대로 만들어서 사용하면 됨!!!!!\n",
        "# : 모델의 구조를 만들어 주는 함수!!! ( oputna의 obj와는 다른 함수!!!!!)"
      ],
      "metadata": {
        "id": "zycxkRZLrVud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model( num_layers_conv1, num_filters_conv1,\n",
        "                 num_layers_conv2, num_filters_conv2,\n",
        "                  dnn_dropout_rate, dnn_num_node):\n",
        "    # 여기서는 모델들을 설계하는 방법에 대한 파라미터들을 받아서 생성!!!\n",
        "    # VGG가 적층 구조 방식이여서 layer들을 모델 구조에 append 하는 방식!!!\n",
        "    # 참고 : 모델 구조가 적층 방식이 아니면, in/out의 구조로 모델을 작성해야 함!!!\n",
        "    model = tf.keras.Sequential()\n",
        "    # 1번 conv block\n",
        "    model.add( Conv2D( input_shape=(28,28,1), kernel_size=(3,3),\n",
        "               filters = 32, padding=\"same\", activation=\"relu\") )\n",
        "    for i in range(num_layers_conv1): # 숫자만큰 conv 레이어 추가!!!\n",
        "        model.add( Conv2D(  kernel_size=(3,3),\n",
        "               filters = num_filters_conv1,\n",
        "                    padding=\"same\", activation=\"relu\"))\n",
        "    model.add( MaxPool2D( pool_size=(2,2), strides=(2,2)) )\n",
        "    # ----------------------------\n",
        "\n",
        "    # 2번 conv block\n",
        "    model.add( Conv2D(  kernel_size=(3,3),\n",
        "               filters = 64, padding=\"same\", activation=\"relu\") )\n",
        "    for i in range(num_layers_conv2): # 숫자만큰 conv 레이어 추가!!!\n",
        "        model.add( Conv2D(  kernel_size=(3,3),\n",
        "               filters = num_filters_conv2,\n",
        "                    padding=\"same\", activation=\"relu\"))\n",
        "    model.add( MaxPool2D( pool_size=(2,2), strides=(2,2)) )\n",
        "\n",
        "    # 분류를 위한 모델 설계\n",
        "    model.add( Flatten())\n",
        "    model.add( Dense( units =dnn_num_node , activation=\"relu\") )\n",
        "    model.add( Dropout( rate = dnn_dropout_rate ))\n",
        "    model.add( Dense( units =dnn_num_node , activation=\"relu\") )\n",
        "    model.add( Dropout( rate = dnn_dropout_rate ))\n",
        "    # ==> hidden layer의 수도 변수화 가능함!!!!!\n",
        "\n",
        "    # 최종 출력용 ==> 고정!!!!!!!!\n",
        "    model.add( Dense( units = 10, activation=\"softmax\"))\n",
        "\n",
        "    # 함수의 목적 : 출력물 --> 모델 구조도!!!\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "acpUOStcrVxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "U09EQBUGvq8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step2) 최적의 값을 찾는 objective function 설계!!!\n",
        "# ==> ML과 유사하게 생성하면 됨!!!!\n",
        "def objective_vgg( trail ):\n",
        "    # 혹시 뒤에 keras 백단에서 살아있는 경우가 있음...\n",
        "    keras.backend.clear_session()\n",
        "    # ---> GPU의 메모리나 이런 부분이 클리어가 안 되는 경우가 있음!!!\n",
        "\n",
        "    # 내가 테스트할 파라미터들을 제안 받는 것들에 대한 세팅!!!!\n",
        "    num_layers_conv1=trail.suggest_int(\"num_layers_conv1\", 1,5)\n",
        "    num_filters_conv1=trail.suggest_int(\"num_filters_conv1\", 32 , 256)\n",
        "    num_layers_conv2= trail.suggest_int(\"num_layers_conv2\", 1,5)\n",
        "    num_filters_conv2=trail.suggest_int(\"num_filters_conv2\", 128 , 512)\n",
        "    dnn_dropout_rate=trail.suggest_float(\"dnn_dropout_rate\", 0.1, 0.3 )\n",
        "    dnn_num_node=trail.suggest_int(\"dnn_num_node\", 256, 4096)\n",
        "    # ++++ 본인이 앞에서 세팅한 모델 구조 함수에 대한 파라미터에 대한 제안!!!\n",
        "    # ---------------------------------------------------------------------\n",
        "\n",
        "\n",
        "    # +++ 모델의 학습하는 영향을 미치는 파라미터도 중요함!!!\n",
        "    # learning rate에 관련된 부분이 중요함!!!!!\n",
        "    # + batch_size, eopoch etc,,,,,,\n",
        "    optimizer = trail.suggest_categorical( \"optimizer\", [\"adam\",\"sgd\"])\n",
        "    # ==> 최적화 방식도 실험으로 할 수 있고,,,,lr조절을 하면 됨!!!!!\n",
        "\n",
        "    model = create_model( num_layers_conv1, num_filters_conv1,\n",
        "                 num_layers_conv2, num_filters_conv2,\n",
        "                  dnn_dropout_rate, dnn_num_node)\n",
        "    model.compile(\n",
        "        optimizer= optimizer,\n",
        "        loss = \"sparse_categorical_crossentropy\",\n",
        "        metrics = [\"accuracy\"]\n",
        "    )\n",
        "    # ---> 제안 받은 모델의 구조 & 어떻게 학습할지에 대한 세팅!!!!!\n",
        "\n",
        "    # + 시간 관계상 수업에서는 callback은 생략!!!\n",
        "    history = model.fit( train_X, train_y,\n",
        "                        epochs = 2, # 시간 관계상 줄이겠습니다!!!!!\n",
        "                        validation_split = 0.25,\n",
        "                        batch_size = 1024,\n",
        "    # +++ callback\n",
        "    #callbacks = [cp_callback,es_callback ]\n",
        "    )\n",
        "\n",
        "    # object function 타켓!!!!!!\n",
        "    # ==> 주관적으로 본인이 선택을 하시면 됨!!!!!!!!!!\n",
        "    # 저는 여기서는 val_accuracy\n",
        "    score = history.history[\"val_accuracy\"][-1]\n",
        "    return score"
      ],
      "metadata": {
        "id": "RAHvE64rrVz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step3)  optuna를 통한 실험!!!\n",
        "study_my_vgg = optuna.create_study( direction=\"maximize\")\n",
        "# 왜? 내가 objective fuinction을 val_accuracy로 했기에.....\n",
        "study_my_vgg.optimize( objective_vgg, n_trials=2, n_jobs=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClaHQq3zykNi",
        "outputId": "e7e831ea-b271-4eb9-f495-67a3a1c2c950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-10-21 01:59:03,694] A new study created in memory with name: no-name-d32ba7e5-4678-4bdd-9133-9f30c9bbc92f\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "Epoch 1/2\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 5s/step - accuracy: 0.1394 - loss: 2.3017 - val_accuracy: 0.2063 - val_loss: 2.2991\n",
            "Epoch 2/2\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 5s/step - accuracy: 0.1926 - loss: 2.3017 - val_accuracy: 0.2818 - val_loss: 2.2997\n",
            "Epoch 2/2\n",
            "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 3s/step - accuracy: 0.2753 - loss: 2.2994 - val_accuracy: 0.3355 - val_loss: 2.2975\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-10-21 02:06:19,205] Trial 0 finished with value: 0.3355333209037781 and parameters: {'num_layers_conv1': 5, 'num_filters_conv1': 217, 'num_layers_conv2': 3, 'num_filters_conv2': 323, 'dnn_dropout_rate': 0.2352554208756247, 'dnn_num_node': 632, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.3355333209037781.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 3s/step - accuracy: 0.2311 - loss: 2.2990 - val_accuracy: 0.2737 - val_loss: 2.2965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-10-21 02:06:51,102] Trial 1 finished with value: 0.27373334765434265 and parameters: {'num_layers_conv1': 1, 'num_filters_conv1': 103, 'num_layers_conv2': 5, 'num_filters_conv2': 148, 'dnn_dropout_rate': 0.2568319779055963, 'dnn_num_node': 759, 'optimizer': 'sgd'}. Best is trial 0 with value: 0.3355333209037781.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 일반적으로는 epoch를 늘려서 하고, ES을 통해서 stop+ CP\n",
        "# ===> 이것으로만 하기에는 조금 애매한 부분들이 있어서,,,\n",
        "#      보통은 정말로 최적화가 필요할 때..( 기본 구조가 정해져있는 상태!! )\n",
        "#      대회 출전 or 논문 제출할 때 수치 올리기 위해서 체크!!!!!\n",
        "# +++ 최신 경향을 먼저( 기본 구조에 대해서 먼저 체크!! )\n",
        "#     그 이후에 시간이 남거나, 투자해서 최적화를 해야한다면,,,시도!!!!!!"
      ],
      "metadata": {
        "id": "iQI0YYP4ykQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8DxJtlprykTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hhFGX1G_ykVo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}